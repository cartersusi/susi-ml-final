import os
import random

import kagglehub
import matplotlib.pyplot as plt
import torch
from torch.utils.data import DataLoader, Subset, random_split
from torchvision import datasets, transforms
from torchvision.transforms import v2 as T


class Dataset:
    def __init__(self, fpath, imsize: tuple[int, int] = (128, 128)):
        self.data_path = fpath
        self.dataset = datasets.ImageFolder(root=fpath)

        # Training image transforms (70% training)
        self.train_transform = transforms.Compose(
            [
                transforms.Resize(imsize),  # Resize all images to 150Ã—150 pixels
                transforms.RandomHorizontalFlip(),  # Apply basic data augmentation (horizontal flip)
                transforms.RandomRotation(
                    15
                ),  # Apply basic data augmentation (rotation)
                transforms.ToTensor(),  # Normalize pixel values to [0, 1] range
                transforms.RandomApply(
                    [T.GaussianNoise(mean=0.0, sigma=0.20, clip=True)],
                    p=0.5,  # Apply max-noise of 0.20 with 50% probability - from Bonus project
                ),
            ]
        )

        # Validation image transforms (15% validation)
        self.validation_transform = transforms.Compose(
            [
                transforms.Resize(imsize),
                transforms.ToTensor(),
            ]
        )

        # Test image transforms (15% val)
        self.test_transform = self.validation_transform

    @property
    def data_size(self) -> int:
        return len(self.dataset)

    @property
    def train_size(self) -> int:
        return int(0.7 * self.data_size)

    @property
    def validation_size(self) -> int:
        return int(0.15 * self.data_size)

    @property
    def test_size(self) -> int:
        return int(self.data_size - self.train_size - self.validation_size)

    def preprocess(self):
        if not self.dataset:
            raise Exception("Dataset must be loaded before preprocessing.")

        train_start, validation_start, test_start = random_split(
            self.dataset, [self.train_size, self.validation_size, self.test_size]
        )

        self.train_data = Subset(
            datasets.ImageFolder(self.data_path, transform=self.train_transform),
            train_start.indices,
        )
        self.val_data = Subset(
            datasets.ImageFolder(self.data_path, transform=self.validation_transform),
            validation_start.indices,
        )
        self.test_data = Subset(
            datasets.ImageFolder(self.data_path, transform=self.test_transform),
            test_start.indices,
        )

    def show_samples(self, train_data=False):
        cats = [
            i for i, (path, label) in enumerate(self.dataset.samples) if "Cat" in path
        ]
        dogs = [
            i for i, (path, label) in enumerate(self.dataset.samples) if "Dog" in path
        ]

        sample_cats = random.sample(cats, min(10, len(cats)))
        sample_dogs = random.sample(dogs, min(10, len(dogs)))

        title = "Augmented Images" if train_data else "Original Images"
        fig, axes = plt.subplots(4, 5, figsize=(15, 12))
        fig.suptitle(title, fontsize=16)

        for idx, ax in enumerate(axes.flat):
            img_idx = sample_cats[idx % 10] if idx < 10 else sample_dogs[idx % 10]
            img, _ = self.dataset[img_idx]

            if train_data:
                img = self.train_transform(img).permute(1, 2, 0).numpy()

            ax.imshow(img)
            ax.set_title("Cat" if idx < 10 else "Dog")
            ax.axis("off")

        plt.tight_layout()
        plt.show()

    def augment(self, datatype: str):
        torch.manual_seed(42)

        if datatype == "train":
            return DataLoader(
                self.train_data, batch_size=32, shuffle=True, num_workers=os.cpu_count()
            )
        else:
            return DataLoader(
                self.val_data, batch_size=32, shuffle=True, num_workers=os.cpu_count()
            )


def cat_dog_download(kaggle_creds: str) -> str:
    if not os.path.exists(kaggle_creds):
        print("Unable to find credentials")
        return ""

    dataset_path = _find_image_folder(
        kagglehub.dataset_download("karakaggle/kaggle-cat-vs-dog-dataset")
    )
    print(f"Kaggle Dataset at: {dataset_path}")

    return dataset_path


def _find_image_folder(root_path: str) -> str:
    for dirpath, dirnames, _ in os.walk(root_path):
        if "Cat" in dirnames and "Dog" in dirnames:
            return dirpath
    return ""
